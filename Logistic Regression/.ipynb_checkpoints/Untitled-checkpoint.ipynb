{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>gmat</th><th>gpa</th><th>work_experience</th><th>admitted</th></tr><tr><th></th><th>Int64</th><th>Float64</th><th>Int64</th><th>Int64</th></tr></thead><tbody><p>40 rows × 4 columns</p><tr><th>1</th><td>780</td><td>4.0</td><td>3</td><td>1</td></tr><tr><th>2</th><td>750</td><td>3.9</td><td>4</td><td>1</td></tr><tr><th>3</th><td>690</td><td>3.3</td><td>3</td><td>0</td></tr><tr><th>4</th><td>710</td><td>3.7</td><td>5</td><td>1</td></tr><tr><th>5</th><td>680</td><td>3.9</td><td>4</td><td>0</td></tr><tr><th>6</th><td>730</td><td>3.7</td><td>6</td><td>1</td></tr><tr><th>7</th><td>690</td><td>2.3</td><td>1</td><td>0</td></tr><tr><th>8</th><td>720</td><td>3.3</td><td>4</td><td>1</td></tr><tr><th>9</th><td>740</td><td>3.3</td><td>5</td><td>1</td></tr><tr><th>10</th><td>690</td><td>1.7</td><td>1</td><td>0</td></tr><tr><th>11</th><td>610</td><td>2.7</td><td>3</td><td>0</td></tr><tr><th>12</th><td>690</td><td>3.7</td><td>5</td><td>1</td></tr><tr><th>13</th><td>710</td><td>3.7</td><td>6</td><td>1</td></tr><tr><th>14</th><td>680</td><td>3.3</td><td>4</td><td>0</td></tr><tr><th>15</th><td>770</td><td>3.3</td><td>3</td><td>1</td></tr><tr><th>16</th><td>610</td><td>3.0</td><td>1</td><td>0</td></tr><tr><th>17</th><td>580</td><td>2.7</td><td>4</td><td>0</td></tr><tr><th>18</th><td>650</td><td>3.7</td><td>6</td><td>1</td></tr><tr><th>19</th><td>540</td><td>2.7</td><td>2</td><td>0</td></tr><tr><th>20</th><td>590</td><td>2.3</td><td>3</td><td>0</td></tr><tr><th>21</th><td>620</td><td>3.3</td><td>2</td><td>1</td></tr><tr><th>22</th><td>600</td><td>2.0</td><td>1</td><td>0</td></tr><tr><th>23</th><td>550</td><td>2.3</td><td>4</td><td>0</td></tr><tr><th>24</th><td>550</td><td>2.7</td><td>1</td><td>0</td></tr><tr><th>25</th><td>570</td><td>3.0</td><td>2</td><td>0</td></tr><tr><th>26</th><td>670</td><td>3.3</td><td>6</td><td>1</td></tr><tr><th>27</th><td>660</td><td>3.7</td><td>4</td><td>1</td></tr><tr><th>28</th><td>580</td><td>2.3</td><td>2</td><td>0</td></tr><tr><th>29</th><td>650</td><td>3.7</td><td>6</td><td>1</td></tr><tr><th>30</th><td>660</td><td>3.3</td><td>5</td><td>1</td></tr><tr><th>&vellip;</th><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccc}\n",
       "\t& gmat & gpa & work\\_experience & admitted\\\\\n",
       "\t\\hline\n",
       "\t& Int64 & Float64 & Int64 & Int64\\\\\n",
       "\t\\hline\n",
       "\t1 & 780 & 4.0 & 3 & 1 \\\\\n",
       "\t2 & 750 & 3.9 & 4 & 1 \\\\\n",
       "\t3 & 690 & 3.3 & 3 & 0 \\\\\n",
       "\t4 & 710 & 3.7 & 5 & 1 \\\\\n",
       "\t5 & 680 & 3.9 & 4 & 0 \\\\\n",
       "\t6 & 730 & 3.7 & 6 & 1 \\\\\n",
       "\t7 & 690 & 2.3 & 1 & 0 \\\\\n",
       "\t8 & 720 & 3.3 & 4 & 1 \\\\\n",
       "\t9 & 740 & 3.3 & 5 & 1 \\\\\n",
       "\t10 & 690 & 1.7 & 1 & 0 \\\\\n",
       "\t11 & 610 & 2.7 & 3 & 0 \\\\\n",
       "\t12 & 690 & 3.7 & 5 & 1 \\\\\n",
       "\t13 & 710 & 3.7 & 6 & 1 \\\\\n",
       "\t14 & 680 & 3.3 & 4 & 0 \\\\\n",
       "\t15 & 770 & 3.3 & 3 & 1 \\\\\n",
       "\t16 & 610 & 3.0 & 1 & 0 \\\\\n",
       "\t17 & 580 & 2.7 & 4 & 0 \\\\\n",
       "\t18 & 650 & 3.7 & 6 & 1 \\\\\n",
       "\t19 & 540 & 2.7 & 2 & 0 \\\\\n",
       "\t20 & 590 & 2.3 & 3 & 0 \\\\\n",
       "\t21 & 620 & 3.3 & 2 & 1 \\\\\n",
       "\t22 & 600 & 2.0 & 1 & 0 \\\\\n",
       "\t23 & 550 & 2.3 & 4 & 0 \\\\\n",
       "\t24 & 550 & 2.7 & 1 & 0 \\\\\n",
       "\t25 & 570 & 3.0 & 2 & 0 \\\\\n",
       "\t26 & 670 & 3.3 & 6 & 1 \\\\\n",
       "\t27 & 660 & 3.7 & 4 & 1 \\\\\n",
       "\t28 & 580 & 2.3 & 2 & 0 \\\\\n",
       "\t29 & 650 & 3.7 & 6 & 1 \\\\\n",
       "\t30 & 660 & 3.3 & 5 & 1 \\\\\n",
       "\t$\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "40×4 DataFrame\n",
       "│ Row │ gmat  │ gpa     │ work_experience │ admitted │\n",
       "│     │ \u001b[90mInt64\u001b[39m │ \u001b[90mFloat64\u001b[39m │ \u001b[90mInt64\u001b[39m           │ \u001b[90mInt64\u001b[39m    │\n",
       "├─────┼───────┼─────────┼─────────────────┼──────────┤\n",
       "│ 1   │ 780   │ 4.0     │ 3               │ 1        │\n",
       "│ 2   │ 750   │ 3.9     │ 4               │ 1        │\n",
       "│ 3   │ 690   │ 3.3     │ 3               │ 0        │\n",
       "│ 4   │ 710   │ 3.7     │ 5               │ 1        │\n",
       "│ 5   │ 680   │ 3.9     │ 4               │ 0        │\n",
       "│ 6   │ 730   │ 3.7     │ 6               │ 1        │\n",
       "│ 7   │ 690   │ 2.3     │ 1               │ 0        │\n",
       "│ 8   │ 720   │ 3.3     │ 4               │ 1        │\n",
       "│ 9   │ 740   │ 3.3     │ 5               │ 1        │\n",
       "│ 10  │ 690   │ 1.7     │ 1               │ 0        │\n",
       "⋮\n",
       "│ 30  │ 660   │ 3.3     │ 5               │ 1        │\n",
       "│ 31  │ 640   │ 3.0     │ 1               │ 0        │\n",
       "│ 32  │ 620   │ 2.7     │ 2               │ 0        │\n",
       "│ 33  │ 660   │ 4.0     │ 4               │ 1        │\n",
       "│ 34  │ 660   │ 3.3     │ 6               │ 1        │\n",
       "│ 35  │ 680   │ 3.3     │ 5               │ 1        │\n",
       "│ 36  │ 650   │ 2.3     │ 1               │ 0        │\n",
       "│ 37  │ 670   │ 2.7     │ 2               │ 0        │\n",
       "│ 38  │ 580   │ 3.3     │ 1               │ 0        │\n",
       "│ 39  │ 590   │ 1.7     │ 4               │ 0        │\n",
       "│ 40  │ 690   │ 3.7     │ 5               │ 1        │"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using CSV\n",
    "\n",
    "data = CSV.read(\"candidates_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = [[x[1], x[2], x[3]] for x in zip(data.gmat, data.gpa, data.work_experience)]\n",
    "y_data = [x for x in data.admitted];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "average_cost (generic function with 1 method)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "σ(x) = 1/(1+exp(-x))\n",
    "\n",
    "function cross_entropy_loss(x,y,w,b)\n",
    "    return -y*log(σ(w'x + b)) - (1-y)*log(1-σ(w'x+b))\n",
    "    end \n",
    "function average_cost(features, labels, w, b)\n",
    "    N = length(features)\n",
    "    return (1/N)*sum([cross_entropy_loss(features[i], labels[i],w,b) for i = 1:N])\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "batch_gradient_descent (generic function with 1 method)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function batch_gradient_descent(features,labels,w,b,α)\n",
    "    del_w = [0.0 for i = 1:length(w)]\n",
    "    del_b = 0.0\n",
    "    N = length(features)\n",
    "    for i = 1:N\n",
    "        del_w += (σ(w'features[i] + b) - labels[i])*features[i]\n",
    "        del_b += (σ(w'features[i] + b) - labels[i])\n",
    "    end\n",
    "    w = w - α*del_w\n",
    "    b = b - α*del_b\n",
    "    return w,b\n",
    "    end "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.012, 0.0006000000000000002, 0.00215], -0.0001)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w,b = batch_gradient_descent(x_data, y_data, [0.0,0.0,0.0], 0.0, .0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train_batch_gradient_descent (generic function with 1 method)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function train_batch_gradient_descent(features,labels, w,b,α, epochs)\n",
    "    \n",
    "    for i = 1:epochs\n",
    "        \n",
    "        w, b = batch_gradient_descent(features, labels, w,b,α)\n",
    "        \n",
    "        if i == 1\n",
    "            println(\"Epochs \", i , \" with loss \", average_cost(x_data, y_data,w,b))\n",
    "        end\n",
    "        if i == 100\n",
    "            println(\"Epochs \", i , \" with loss \", average_cost(x_data, y_data,w,b))\n",
    "        end\n",
    "        if i == 1000\n",
    "            println(\"Epochs \", i , \" with loss \", average_cost(x_data, y_data,w,b))\n",
    "        end\n",
    "        if i == 10000\n",
    "            println(\"Epochs \", i , \" with loss \", average_cost(x_data, y_data,w,b))\n",
    "        end\n",
    "        if i == 100000\n",
    "            println(\"Epochs \", i , \" with loss \", average_cost(x_data, y_data,w,b))\n",
    "        end\n",
    "        if i == 1000000\n",
    "            println(\"Epochs \", i , \" with loss \", average_cost(x_data, y_data,w,b))\n",
    "        end\n",
    "        end \n",
    "    return w,b\n",
    "    end \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs 1 with loss 0.6935528232717131\n",
      "Epochs 100 with loss 1.95992233790548\n",
      "Epochs 1000 with loss 1.9483437679105173\n",
      "Epochs 10000 with loss 1.8384129779157607\n",
      "Epochs 100000 with loss 0.5857047037944411\n",
      "Epochs 1000000 with loss 0.42154237597461663\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([-0.014627310541781454, 1.6446557866194398, 1.2445708637797013], -0.8369315573146886)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = [0.0,0.0,0.0]\n",
    "b = 0.0\n",
    "\n",
    "w,b = train_batch_gradient_descent(x_data,y_data, w,b,0.000001,1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "predict (generic function with 1 method)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function predict(x,y,w,b)\n",
    "    if σ(w'x+b) >= .5\n",
    "        return 1\n",
    "    else\n",
    "        return 0\n",
    "        end \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2"
     ]
    }
   ],
   "source": [
    "mean_error = 0.0\n",
    "for i = 1:length(x_data)\n",
    "    mean_error += (predict(x_data[i], y_data[i], w, b) - y_data[i])^2\n",
    "end\n",
    "print(mean_error/length(x_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.5.0",
   "language": "julia",
   "name": "julia-1.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
