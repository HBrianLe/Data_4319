{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perceptron Python Packages\n",
    "\n",
    "The percetron model is the simplest neural networks architechture that we can be the starting blocks for building a larger Neural Netowrk model that can classify large amounts of objects and units. The Perceptron Model is built on the input of numbers that is associated with an assigned weight, which is used to compute the weighted sum between the input and the weights. The weighted sub is applied to a sign function that will output the results as a binary classifiation of -1 or 1. \n",
    "\n",
    "\n",
    "$$\n",
    "\\text{Sign Function} : \\hat y\n",
    "= \n",
    "\\begin{cases}\n",
    "-1 \\text{ if } \\hat p < 0        \\\\\n",
    "0 \\text{ if } \\hat p = 0        \\\\\n",
    "1 \\text{ if } \\hat p > 0\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "#### Perceptron Training \n",
    "The perceptron model is trained using the error of the network that is produced. In perceptron training, we input on set of data or a data point one at a time, as a result if this results into an error at any point the weights of the model are reinforced or updated to reflect the changed in the weights. The update result is shown in the new weights at each learning period. The leanring model can be shown below, in this leaning rule:\n",
    "\n",
    "$$ w_{i,j}  = w_{i,j} + \\eta(y_j - \\hat{y_j} )  x_i$$\n",
    "\n",
    "In this equation:\n",
    "- $w_{i,j}$ is the weight amount associated with each neuron connection point in our model. The $i^{th}$ input with the $j^{th}$ output neuron.\n",
    "- $x_i$ is the $i^{th}$ input value of the training value.\n",
    "- $\\hat{y_j}$ is the output of the $j^{th}$ output neuron for the current training value.\n",
    "- $y_j$ is the target output of the $j^{th}$ output neuron for the current training value. \n",
    "- $\\eta$ is the learning rate for our model\n",
    "\n",
    "\n",
    "____\n",
    "\n",
    "Here we will use scikit learn packages to do the perceptron model. We will the the Perceptron model that is built in to make our model and use other packages as a method to process data. \n",
    "\n",
    "\n",
    "Below, we import our needed packages from sklearn\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using the iris dataset for this perceptron model. We can use the preloaded dataset in sklearn and import them here. They will be a bunch tied together but we can seprate the data and the target into arrays. We will label this X and Y datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "\n",
    "X = iris.data\n",
    "y = iris.target\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we load ourdata, we might want to provide a split for the data. For training and testing. The data we have for the iris dataset is small and it may not be as much as we want to have a train and test split on but our model should run. It is more ideal to have more of a higher count for the split to be productive. We will use a 70-30 split to train and test our model.\n",
    "\n",
    "We can also then standardize our data for the model to provide accurate results that are similar to the rest of the data and make sure the data is not have diffrent units when testing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 438,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc = StandardScaler()\n",
    "sc.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_std = sc.transform(X_train)\n",
    "\n",
    "X_test_std = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Perceptron(alpha=0.0001, class_weight=None, early_stopping=False, eta0=1.0,\n",
       "           fit_intercept=True, max_iter=1000, n_iter_no_change=5, n_jobs=None,\n",
       "           penalty=None, random_state=0, shuffle=True, tol=0.001,\n",
       "           validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 440,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ppn = Perceptron(tol = .001, random_state=0)\n",
    "\n",
    "# Train the perceptron\n",
    "ppn.fit(X_train_std, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = ppn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True, False,  True,  True,  True, False,  True,\n",
       "       False,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "       False,  True,  True, False,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True, False,  True,  True,  True,\n",
       "       False,  True,  True,  True,  True,  True,  True,  True,  True])"
      ]
     },
     "execution_count": 442,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred == y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.82\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: %.2f' % accuracy_score(y_pred, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
